{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62bbc74b-abd1-4fd0-bdc5-573b010bed72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5232 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "81/81 [==============================] - 103s 1s/step - loss: 0.4309 - accuracy: 0.8440 - val_loss: 0.2569 - val_accuracy: 0.9028 - lr: 1.0000e-04\n",
      "Epoch 2/15\n",
      "81/81 [==============================] - 99s 1s/step - loss: 0.2303 - accuracy: 0.9292 - val_loss: 0.3423 - val_accuracy: 0.8993 - lr: 1.0000e-04\n",
      "Epoch 3/15\n",
      "81/81 [==============================] - 100s 1s/step - loss: 0.1884 - accuracy: 0.9421 - val_loss: 0.5102 - val_accuracy: 0.8455 - lr: 1.0000e-04\n",
      "Epoch 4/15\n",
      "81/81 [==============================] - 100s 1s/step - loss: 0.1560 - accuracy: 0.9516 - val_loss: 0.5244 - val_accuracy: 0.8472 - lr: 1.0000e-04\n",
      "Epoch 5/15\n",
      "81/81 [==============================] - 100s 1s/step - loss: 0.1527 - accuracy: 0.9539 - val_loss: 0.3870 - val_accuracy: 0.8993 - lr: 1.0000e-04\n",
      "Epoch 6/15\n",
      "81/81 [==============================] - 100s 1s/step - loss: 0.1406 - accuracy: 0.9634 - val_loss: 0.3326 - val_accuracy: 0.9115 - lr: 1.0000e-04\n",
      "Epoch 7/15\n",
      "81/81 [==============================] - 100s 1s/step - loss: 0.1034 - accuracy: 0.9681 - val_loss: 0.2193 - val_accuracy: 0.9184 - lr: 2.0000e-05\n",
      "Epoch 8/15\n",
      "81/81 [==============================] - 101s 1s/step - loss: 0.1043 - accuracy: 0.9710 - val_loss: 0.2355 - val_accuracy: 0.9184 - lr: 2.0000e-05\n",
      "Epoch 9/15\n",
      "81/81 [==============================] - 100s 1s/step - loss: 0.0935 - accuracy: 0.9721 - val_loss: 0.3661 - val_accuracy: 0.9115 - lr: 2.0000e-05\n",
      "Epoch 10/15\n",
      "81/81 [==============================] - 99s 1s/step - loss: 0.0965 - accuracy: 0.9716 - val_loss: 0.2725 - val_accuracy: 0.9062 - lr: 2.0000e-05\n",
      "Epoch 11/15\n",
      "81/81 [==============================] - 100s 1s/step - loss: 0.0945 - accuracy: 0.9712 - val_loss: 0.2332 - val_accuracy: 0.9115 - lr: 2.0000e-05\n",
      "Epoch 12/15\n",
      "81/81 [==============================] - 100s 1s/step - loss: 0.0831 - accuracy: 0.9752 - val_loss: 0.1957 - val_accuracy: 0.9358 - lr: 2.0000e-05\n",
      "Epoch 13/15\n",
      "81/81 [==============================] - 100s 1s/step - loss: 0.0864 - accuracy: 0.9727 - val_loss: 0.2068 - val_accuracy: 0.9271 - lr: 2.0000e-05\n",
      "Epoch 14/15\n",
      "81/81 [==============================] - 98s 1s/step - loss: 0.0917 - accuracy: 0.9712 - val_loss: 0.2372 - val_accuracy: 0.9253 - lr: 2.0000e-05\n",
      "Epoch 15/15\n",
      "81/81 [==============================] - 98s 1s/step - loss: 0.0850 - accuracy: 0.9727 - val_loss: 0.2341 - val_accuracy: 0.9184 - lr: 2.0000e-05\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define data generators with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_dir = '/Users/isabel/desktop/CHEST-XRAY/chest_xray/train'\n",
    "val_dir = '/Users/isabel/desktop/CHEST-XRAY/chest_xray/test'\n",
    "\n",
    "# Batch size (increase for better convergence)\n",
    "batch_size = 64\n",
    "\n",
    "try:\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(224, 224),  # VGG16 input size\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary' \n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary'  \n",
    "    )\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Error: Directory not found. Please check your file paths.\")\n",
    "    raise e\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Fine-tune the last few layers of the base model\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model on top of the pre-trained base with regularisation\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Define a custom learning rate scheduler function\n",
    "def lr_scheduler(epoch):\n",
    "    initial_learning_rate = 1e-4\n",
    "    lr = initial_learning_rate * tf.math.pow(0.9, epoch // 5)  # Decay every 5 epochs\n",
    "    return lr\n",
    "\n",
    "# Compile the model with appropriate loss + metrics\n",
    "model.compile(optimizer=Adam(learning_rate=lr_scheduler(0)), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping and reduce learning rate on plateau\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "epochs = 15  \n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size,\n",
    "    callbacks=[early_stopping, reduce_lr_on_plateau]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "718b3257-3c97-4039-b642-1f483d897fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 9s 873ms/step - loss: 0.2254 - accuracy: 0.9215\n",
      "Validation Loss: 0.2253951132297516\n",
      "Validation Accuracy: 0.9214743971824646\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation data\n",
    "eval_result = model.evaluate(val_generator)\n",
    "\n",
    "# Print the evaluation result\n",
    "print(\"Validation Loss:\", eval_result[0])\n",
    "print(\"Validation Accuracy:\", eval_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e52b453d-327d-4ba1-8e20-876ee469b9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CHESTXRAY.KERAS/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CHESTXRAY.KERAS/assets\n"
     ]
    }
   ],
   "source": [
    "# After training is complete\n",
    "model.save(\"CHESTXRAY.KERAS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e42bb-5734-491b-b05e-ea281e2e06c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03795a2-64da-4dc8-a3ab-189e5e7f646d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
